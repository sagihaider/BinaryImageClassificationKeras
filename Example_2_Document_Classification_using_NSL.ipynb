{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example_2_Document_Classification_using_NSL.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sagihaider/BinaryImageClassificationKeras/blob/master/Example_2_Document_Classification_using_NSL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P_w2j3V7Him",
        "colab_type": "code",
        "outputId": "5974d35e-4e7d-42d9-e455-403016be2574",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  !pip install tensorflow-gpu>=2.0.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oh8FcoMXAzGA",
        "colab_type": "code",
        "outputId": "43ad96b9-746d-4918-f11b-d1539d980e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install --quiet neural-structured-learning"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▏                            | 10kB 21.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 3.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0U4zxiOA32k",
        "colab_type": "code",
        "outputId": "8fc2eaac-b5f5-48ce-fad2-0a8970dc0667",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import neural_structured_learning as nsl\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Resets notebook state\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  2.0.0\n",
            "Eager mode:  True\n",
            "GPU is available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whARn1JCBhml",
        "colab_type": "code",
        "outputId": "9c57bdf9-e246-4119-e877-09b33c25007d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Download Cora Dataset\n",
        "!wget --quiet -P /tmp https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\n",
        "!tar -C /tmp -xvzf /tmp/cora.tgz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cora/\n",
            "cora/README\n",
            "cora/cora.content\n",
            "cora/cora.cites\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ix82kHZlG1Ca",
        "colab_type": "code",
        "outputId": "2ce5167c-3b68-4873-8244-a93ff1972e24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/tensorflow/neural-structured-learning/master/neural_structured_learning/examples/preprocess/cora/preprocess_cora_dataset.py\n",
        "\n",
        "!python preprocess_cora_dataset.py \\\n",
        "--input_cora_content=/tmp/cora/cora.content \\\n",
        "--input_cora_graph=/tmp/cora/cora.cites \\\n",
        "--max_nbrs=5 \\\n",
        "--output_train_data=/tmp/cora/train_merged_examples.tfr \\\n",
        "--output_test_data=/tmp/cora/test_examples.tfr"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-18 20:31:54--  https://raw.githubusercontent.com/tensorflow/neural-structured-learning/master/neural_structured_learning/examples/preprocess/cora/preprocess_cora_dataset.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11419 (11K) [text/plain]\n",
            "Saving to: ‘preprocess_cora_dataset.py’\n",
            "\n",
            "\r          preproces   0%[                    ]       0  --.-KB/s               \rpreprocess_cora_dat 100%[===================>]  11.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-10-18 20:31:54 (144 MB/s) - ‘preprocess_cora_dataset.py’ saved [11419/11419]\n",
            "\n",
            "Reading graph file: /tmp/cora/cora.cites...\n",
            "Done reading 5429 edges from: /tmp/cora/cora.cites (0.01 seconds).\n",
            "Making all edges bi-directional...\n",
            "Done (0.01 seconds). Total graph nodes: 2708\n",
            "Joining seed and neighbor tf.train.Examples with graph edges...\n",
            "Done creating and writing 2155 merged tf.train.Examples (1.35 seconds).\n",
            "Out-degree histogram: [(1, 386), (2, 468), (3, 452), (4, 309), (5, 540)]\n",
            "Output training data written to TFRecord file: /tmp/cora/train_merged_examples.tfr.\n",
            "Output test data written to TFRecord file: /tmp/cora/test_examples.tfr.\n",
            "Total running time: 0.04 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LQU4X6EBosl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Experiment dataset\n",
        "TRAIN_DATA_PATH = '/tmp/cora/train_merged_examples.tfr'\n",
        "TEST_DATA_PATH = '/tmp/cora/test_examples.tfr'\n",
        "\n",
        "### Constants used to identify neighbor features in the input.\n",
        "NBR_FEATURE_PREFIX = 'NL_nbr_'\n",
        "NBR_WEIGHT_SUFFIX = '_weight'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dsSsrgokhDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HParams(object):\n",
        "  \"\"\"Hyperparameters used for training.\"\"\"\n",
        "  def __init__(self):\n",
        "    ### dataset parameters\n",
        "    self.num_classes = 7\n",
        "    self.max_seq_length = 1433\n",
        "    ### neural graph learning parameters\n",
        "    self.distance_type = nsl.configs.DistanceType.L2\n",
        "    self.graph_regularization_multiplier = 0.1\n",
        "    self.num_neighbors = 1\n",
        "    ### model architecture\n",
        "    self.num_fc_units = [50, 50]\n",
        "    ### training parameters\n",
        "    self.train_epochs = 100\n",
        "    self.batch_size = 128\n",
        "    self.dropout_rate = 0.5\n",
        "    ### eval parameters\n",
        "    self.eval_steps = None  # All instances in the test set are evaluated.\n",
        "\n",
        "HPARAMS = HParams()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoJ7IJ28kmHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_example(example_proto):\n",
        "  \"\"\"Extracts relevant fields from the `example_proto`.\n",
        "\n",
        "  Args:\n",
        "    example_proto: An instance of `tf.train.Example`.\n",
        "\n",
        "  Returns:\n",
        "    A pair whose first value is a dictionary containing relevant features\n",
        "    and whose second value contains the ground truth labels.\n",
        "  \"\"\"\n",
        "  # The 'words' feature is a multi-hot, bag-of-words representation of the\n",
        "  # original raw text. A default value is required for examples that don't\n",
        "  # have the feature.\n",
        "  feature_spec = {\n",
        "      'words':\n",
        "          tf.io.FixedLenFeature([HPARAMS.max_seq_length],\n",
        "                                tf.int64,\n",
        "                                default_value=tf.constant(\n",
        "                                    0,\n",
        "                                    dtype=tf.int64,\n",
        "                                    shape=[HPARAMS.max_seq_length])),\n",
        "      'label':\n",
        "          tf.io.FixedLenFeature((), tf.int64, default_value=-1),\n",
        "  }\n",
        "  # We also extract corresponding neighbor features in a similar manner to\n",
        "  # the features above.\n",
        "  for i in range(HPARAMS.num_neighbors):\n",
        "    nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, i, 'words')\n",
        "    nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, i, NBR_WEIGHT_SUFFIX)\n",
        "    feature_spec[nbr_feature_key] = tf.io.FixedLenFeature(\n",
        "        [HPARAMS.max_seq_length],\n",
        "        tf.int64,\n",
        "        default_value=tf.constant(\n",
        "            0, dtype=tf.int64, shape=[HPARAMS.max_seq_length]))\n",
        "\n",
        "    # We assign a default value of 0.0 for the neighbor weight so that\n",
        "    # graph regularization is done on samples based on their exact number\n",
        "    # of neighbors. In other words, non-existent neighbors are discounted.\n",
        "    feature_spec[nbr_weight_key] = tf.io.FixedLenFeature(\n",
        "        [1], tf.float32, default_value=tf.constant([0.0]))\n",
        "\n",
        "  features = tf.io.parse_single_example(example_proto, feature_spec)\n",
        "\n",
        "  labels = features.pop('label')\n",
        "  return features, labels\n",
        "\n",
        "\n",
        "def make_dataset(file_path, training=False):\n",
        "  \"\"\"Creates a `tf.data.TFRecordDataset`.\n",
        "\n",
        "  Args:\n",
        "    file_path: Name of the file in the `.tfrecord` format containing\n",
        "      `tf.train.Example` objects.\n",
        "    training: Boolean indicating if we are in training mode.\n",
        "\n",
        "  Returns:\n",
        "    An instance of `tf.data.TFRecordDataset` containing the `tf.train.Example`\n",
        "    objects.\n",
        "  \"\"\"\n",
        "  dataset = tf.data.TFRecordDataset([file_path])\n",
        "  if training:\n",
        "    dataset = dataset.shuffle(10000)\n",
        "  dataset = dataset.map(parse_example)\n",
        "  dataset = dataset.batch(HPARAMS.batch_size)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "train_dataset = make_dataset(TRAIN_DATA_PATH, training=True)\n",
        "test_dataset = make_dataset(TEST_DATA_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}